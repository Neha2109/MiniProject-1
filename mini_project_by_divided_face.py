# -*- coding: utf-8 -*-
"""mini_project_by_divided_face.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1fP0rb8iK2ckLn6FzrcTNybJBWIkFu4A7
"""

import os
import PIL
import cv2
import joblib
import matplotlib
import numpy as np
import pandas as pd
import tensorflow as tf
from sklearn.svm import SVC
from google.colab import drive
import matplotlib.pyplot as plt
from PIL import Image, ImageDraw
from sklearn.metrics import accuracy_score
from google.colab.patches import cv2_imshow
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import classification_report
from sklearn.neighbors import KNeighborsClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn. metrics import confusion_matrix, f1_score

drive.mount('/content/drive')

# Method to draw boundary around the detected feature
def draw_boundary(img, classifier, scaleFactor, minNeighbors, color , index , add , category):
    # Converting image to gray-scale
    gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

    # detecting features in gray-scale image, returns coordinates, width and height of features
    features = classifier.detectMultiScale(gray_img, scaleFactor, minNeighbors)

    coords = []
    # drawing rectangle around the feature and labeling it
    for (x, y, w, h) in features:
        # cv2.rectangle(img, (x,y), (x+w, y+h), color, 2) -----  rectanglehoe
        # cv2.putText(img, text, (x, y-4), cv2.FONT_HERSHEY_SIMPLEX, 0.8, color, 1, cv2.LINE_AA)
        coords = [x, y, w, h]
    crop_img = img[coords[1]:coords[1]+coords[3], coords[0]:coords[0]+coords[2]]
    last_name = str(add)
    if(index == 2):
      Datadirectory = "/content/drive/MyDrive/Mini_project"
      datadirectory = Datadirectory + '/' + category + '/' + '02'
      path=os.path.join(datadirectory,last_name)

      cv2.imwrite(path , crop_img)
    if(index == 1):
      Datadirectory = "/content/drive/MyDrive/Mini_project"
      datadirectory = Datadirectory + '/' + category + '/' + '01'
      path=os.path.join(datadirectory,last_name)
      cv2.imwrite(path , crop_img)
    if(index == 3):
      Datadirectory = "/content/drive/MyDrive/Mini_project"
      datadirectory = Datadirectory + '/' + category + '/' + '03'
      path=os.path.join(datadirectory,last_name)
      cv2.imwrite(path ,crop_img)
    # cv2_imshow(crop_img)

    return coords


# Method to detect the features
def detect(img, faceCascade, eyeCascade, noseCascade, mouthCascade , add , category):
    color = {"blue":(255,0,0), "red":(0,0,255), "green":(0,255,0), "white":(255,255,255)}

    coords = draw_boundary(img, faceCascade, 1.1, 10, color['blue'],0 , add,category)
    # If feature is detected, the draw_boundary method will return the x,y coordinates and width and height of rectangle else the length of coords will be 0
    if len(coords)==4:
        # Updating region of interest by cropping image
        roi_img = img[coords[1]:coords[1]+coords[3], coords[0]:coords[0]+coords[2]]
        # Passing roi, c-lassifier, scaling factor, Minimum neighbours, color, label text
        coords = draw_boundary(roi_img, eyeCascade, 1.1, 12, color['red'] , 1 , add , category)
        coords = draw_boundary(roi_img, noseCascade, 1.1, 4, color['green'], 2 , add , category)
        coords = draw_boundary(roi_img, mouthCascade, 1.1, 6, color['white'], 3 , add , category)
    return img


# Loading classifiers
faceCascade = cv2.CascadeClassifier('/content/drive/MyDrive/Mini_project/Cascade/haarcascade_frontalface_default.xml')
eyesCascade = cv2.CascadeClassifier('/content/drive/MyDrive/Mini_project/Cascade/haarcascade_eye.xml')
noseCascade = cv2.CascadeClassifier('/content/drive/MyDrive/Mini_project/Cascade/Nariz.xml')
mouthCascade = cv2.CascadeClassifier('/content/drive/MyDrive/Mini_project/Cascade/Mouth.xml')

# releasing web-cam
Datadirectory="/content/drive/MyDrive/Mini_project"
classes = ["0","1","2","3","4"];
def create_features():
  for category in classes:
    ad=os.path.join(Datadirectory,category)
    class_num=classes.index(category)
    path = os.path.join(ad,"04")
    # print(path)
    for i in os.listdir(path):
      try:
        img = cv2.imread(path+'/'+str(i))
        img = detect(img, faceCascade, eyesCascade, noseCascade, mouthCascade , i , category)
        # cv2_imshow(img)

      except Exception as e:
        pass

cv2.destroyAllWindows()

create_features()

Datadirectory="/content/drive/MyDrive/Mini_project"

classes = ["0" , "1", "2", "3", "4"]
fer = ["01" , "02", "03", "04"]

# Initialize an empty list to hold the training data
training_Data = [[], [], [], []]

# Define the image size for resizing
img_size = 224

# Function to create training data
def create_training_Data():
    for category in classes:
        # Construct the path to the category folder
        add = os.path.join(Datadirectory, category)

        # Get the class index for the current category
        class_num = classes.index(category)

        # Initialize a counter for each class
        i = 0

        for feature in fer:
            # Construct the path to the specific feature folder
            path = os.path.join(add, feature)

            # Loop through the images in the feature folder
            for img in os.listdir(path):
                try:
                    # Read the image using OpenCV
                    img_array = cv2.imread(os.path.join(path, img))

                    # Resize the image to the specified size
                    new_array = cv2.resize(img_array, (img_size, img_size))

                    # Append the resized image and its class number to the training data list
                    training_Data[i].append([new_array, class_num])

                except Exception as e:
                    # Handle any exceptions that may occur during image processing
                    pass
            i += 1

create_training_Data()

# Initialize a list to hold the data for each class
x = [[], [], [], []]

# Initialize a list to hold the corresponding labels
y = []

# Initialize a counter
i = 0

# Loop through the training data for each class
for sub_fold in training_Data:
    # Print the number of samples in the current class
    print(len(sub_fold))

    # Loop through the features and labels in the current class
    for features, label in sub_fold:
        # Append the features to the appropriate class's data list
        x[i].append(features)

        # If i is 0, add the label to the labels list (assuming labels are the same for all classes)
        if i == 0:
            y.append(label)

    # Increment the counter for the next class
    i += 1

# Convert the lists to NumPy arrays
for i in range(4):
    x[i] = np.array(x[i]).reshape(-1, img_size, img_size, 3)

    # Normalize the image data by dividing by 255 (assuming pixel values are in the range 0-255)
    x[i] = x[i] / 255

    # Convert the array back to a list
    x[i] = list(x[i])

# Convert the data and labels to NumPy arrays
x = np.array(x)
y = np.array(y)

print(x.shape)

"""MACHINE LEARNING PART

"""

# Assuming x contains the data you want to concatenate
data = np.concatenate(x, axis=-1)

# Calculate the size of the data array and set the number of rows for reshaping
num_rows = data.shape[0]
# Calculate the number of columns for reshaping
num_columns = data.size // num_rows

# Reshape the data into a 2D array
x = data.reshape((num_rows, num_columns))

# Split data in 80 , 20 percent.
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)

"""# **LogisticRegression**"""

# Import necessary libraries


# Create a Logistic Regression model
lr = LogisticRegression(max_iter=100)

# Train the model on the training data
lr.fit(x_train, y_train)

# Evaluate the model's accuracy on the test data
accuracy_lr = lr.score(x_test, y_test)

# Print the accuracy
print("Logistic Regression Accuracy:", accuracy_lr)

"""# **Random Forest**"""

# Create a RandomForestClassifier with a random seed for reproducibility
rf = RandomForestClassifier(random_state=42)

# Train the Random Forest model on the training data
rf.fit(x_train, y_train)

# Evaluate the model's accuracy on the test data
accuracy_rf = rf.score(x_test, y_test)

# Print the accuracy of the Random Forest model
print("Random Forest Accuracy:", accuracy_rf)

"""# **Support Vector Machine (SVM)**"""

# Create a Support Vector Machine (SVM) classifier with a random seed for reproducibility
svm = SVC(random_state=42)

# Train the SVM model on the training data
svm.fit(x_train, y_train)

# Evaluate the model's accuracy on the test data
accuracy_svm = svm.score(x_test, y_test)

# Print the accuracy of the SVM model
print("SVM Accuracy:", accuracy_svm)

"""# **K-Nearest Neighbors (KNN)**"""

# Create a KNeighborsClassifier
knn = KNeighborsClassifier()

# Train the KNN model on the training data
knn.fit(x_train, y_train)

# Evaluate the model's accuracy on the test data
accuracy_knn = knn.score(x_test, y_test)

# Print the accuracy of the KNN model
print("KNN Accuracy:", accuracy_knn)

"""# **Decision Tree**"""

# Create a DecisionTreeClassifier with a random seed for reproducibility
dt = DecisionTreeClassifier(random_state=42)

# Train the Decision Tree model on the training data
dt.fit(x_train, y_train)

# Evaluate the model's accuracy on the test data
accuracy_dt = dt.score(x_test, y_test)

# Print the accuracy of the Decision Tree model
print("Decision Tree Accuracy:", accuracy_dt)

"""# **GRADIENT BOOSTING**"""

# Create a Decision Tree Classifier
dt = DecisionTreeClassifier(random_state=42)

# Train the model on the training data
dt.fit(x_train, y_train)

# Evaluate the model's accuracy on the test data
accuracy_dt = dt.score(x_test, y_test)

# Print the accuracy
print("Decision Tree Accuracy:", accuracy_dt)

import numpy as np
import joblib
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
import h5py


# Train a logistic regression model
lr = LogisticRegression(max_iter=100)
lr.fit(x_train, y_train)

# Save the Logistic Regression model using joblib
joblib.dump(lr, 'logistic_regression_model.pkl')


# Now, save the Logistic Regression model as .h5 using h5py
with h5py.File('logistic_regression_model.h5', 'w') as hf:
    # Create a group for the model
    group = hf.create_group("logistic_regression_model")

    # Save the coefficients and intercept separately
    group.create_dataset("coefficients", data=lr.coef_)
    group.create_dataset("intercept", data=lr.intercept_)


accuracy = lr.score(x_test, y_test)
print("Accuracy:", accuracy)

# Create a dictionary to store model names and their corresponding accuracies
model_accuracies = {
    "Logistic Regression": accuracy_lr,
    "Random Forest": accuracy_rf,
    "Support Vector Machine": accuracy_svm,
    "K-Nearest Neighbors": accuracy_knn,
    "Decision Tree": accuracy_dt,
    "GRADIENT BOOSTING":accuracy_dt
}

# Create a DataFrame from the dictionary
accuracy_df = pd.DataFrame(list(model_accuracies.items()), columns=["Model", "Accuracy"])

# Display the accuracy table
print(accuracy_df)

# Import necessary libraries

# Create a list of classifiers
classifiers = [
    DecisionTreeClassifier(),
    RandomForestClassifier(),
    KNeighborsClassifier(),
    SVC(),
    LogisticRegression()
]

# Create a list of classifier names
names = ['Decision Tree', 'Random Forest', 'K-Nearest Neighbors', 'Support Vector Machine', 'Logistic Regression']

# Initialize a list to store accuracies
accuracies = []

# Loop through each classifier, train it, and evaluate accuracy
for clf in classifiers:
    clf.fit(x_train, y_train)
    y_pred = clf.predict(x_test)
    accuracies.append(accuracy_score(y_test, y_pred))

# Plot the results
y_pos = np.arange(len(names))
plt.bar(y_pos, accuracies, align='center', alpha=0.9)
plt.xticks(y_pos, names, rotation=45)
plt.ylabel('Accuracy')
plt.title('Classifier Comparison')
plt.show()

loaded_lr_model = joblib.load('your_model.pkl')

y_pred = lr.predict(x_test)
target_names = ['Openness', 'Conscientiousness' , 'Extraversion' , 'Agreeableness' ]
print(classification_report(y_test, y_pred, target_names=target_names))

target_names = ['Openness', 'Conscientiousness' , 'Extraversion' , 'Agreeableness' , 'Neuroticism']
print("predicted personality : " , target_names[y_pred[1]])

print("Real value :", target_names[y_test[1]])

# Method to draw boundary around the detected feature
Datadirectory="/content/drive/MyDrive/Mini_project"
def draw_boundary(img, classifier, scaleFactor, minNeighbors, color , index , add , category):
    # Converting image to gray-scale

    gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

    # gray_img = img
    # detecting features in gray-scale image, returns coordinates, width and height of features

    features = classifier.detectMultiScale(gray_img, scaleFactor, minNeighbors)

    coords = []
    # drawing rectangle around the feature and labeling it
    for (x, y, w, h) in features:
        # cv2.rectangle(img, (x,y), (x+w, y+h), color, 2) -----  rectanglehoe
        # cv2.putText(img, text, (x, y-4), cv2.FONT_HERSHEY_SIMPLEX, 0.8, color, 1, cv2.LINE_AA)
        coords = [x, y, w, h]
    crop_img = img[coords[1]:coords[1]+coords[3], coords[0]:coords[0]+coords[2]]
    last_name = str(add)
    if(index == 2):
      Datadirectory = "/content/drive/MyDrive/Mini_project"
      datadirectory = Datadirectory + '/' + category + '/' + '02'
      path=os.path.join(datadirectory,last_name)

      cv2.imwrite(path , crop_img)
    if(index == 1):
      Datadirectory = "/content/drive/MyDrive/Mini_project"
      datadirectory = Datadirectory + '/' + category + '/' + '01'
      path=os.path.join(datadirectory,last_name)
      cv2.imwrite(path , crop_img)
    if(index == 3):
      Datadirectory = "/content/drive/MyDrive/Mini_project"
      datadirectory = Datadirectory + '/' + category + '/' + '03'
      path=os.path.join(datadirectory,last_name)
      cv2.imwrite(path ,crop_img)
    # cv2_imshow(crop_img)

    return coords


# Method to detect the features
def detect(img, faceCascade, eyeCascade, noseCascade, mouthCascade , add , category):
    color = {"blue":(255,0,0), "red":(0,0,255), "green":(0,255,0), "white":(255,255,255)}

    coords = draw_boundary(img, faceCascade, 1.1, 10, color['blue'],0 , add,category)
    # If feature is detected, the draw_boundary method will return the x,y coordinates and width and height of rectangle else the length of coords will be 0
    if len(coords)==4:
        # Updating region of interest by cropping image
        roi_img = img[coords[1]:coords[1]+coords[3], coords[0]:coords[0]+coords[2]]
        # Passing roi, c-lassifier, scaling factor, Minimum neighbours, color, label text
        coords = draw_boundary(roi_img, eyeCascade, 1.1, 12, color['red'] , 1 , add , category)
        coords = draw_boundary(roi_img, noseCascade, 1.1, 4, color['green'], 2 , add , category)
        coords = draw_boundary(roi_img, mouthCascade, 1.1, 6, color['white'], 3 , add , category)
    return img


# Loading classifiers
faceCascade = cv2.CascadeClassifier('/content/drive/MyDrive/Mini_project/Cascade/haarcascade_frontalface_default.xml')
eyesCascade = cv2.CascadeClassifier('/content/drive/MyDrive/Mini_project/Cascade/haarcascade_eye.xml')
noseCascade = cv2.CascadeClassifier('/content/drive/MyDrive/Mini_project/Cascade/Nariz.xml')
mouthCascade = cv2.CascadeClassifier('/content/drive/MyDrive/Mini_project/Cascade/Mouth.xml')

# releasing web-cam
Datadirectory="/content/drive/MyDrive/Mini_project"
classes = ["pred"];
def create_pred_features():
  for category in classes:
    ad=os.path.join(Datadirectory,category)
    class_num=classes.index(category)
    path = os.path.join(ad,"04")
    # print(path)
    for i in os.listdir(path):
      try:
        img = cv2.imread(path+'/'+str(i))
        img = detect(img, faceCascade, eyesCascade, noseCascade, mouthCascade , i , category)
        # cv2_imshow(img)

      except Exception as e:
        pass

cv2.destroyAllWindows()

create_pred_features()

classes = ["pred"]
fer = ["01" , "02", "03", "04"]

# Initialize an empty list to hold the prediction data
pred_Data = [[], [], [], []]
# classes = ["pred"]
# fer = ["01" , "02", "03", "04"]
# Datadirectory="/content/drive/MyDrive/Mini_project"

# Define the image size for resizing
img_size = 224

# Function to create prediction data
def create_Pred_Data(classes, Datadirectory, fer):
    for category in classes:
        # Construct the path to the category folder
        add = os.path.join(Datadirectory, category)

        # Get the class index for the current category
        class_num = classes.index(category)

        # Initialize a counter for each class
        i = 0

        for feature in fer:
            # Construct the path to the specific feature folder
            path = os.path.join(add, feature)

            # Loop through the images in the feature folder
            for img in os.listdir(path):
                try:
                    # Read the image using OpenCV
                    img_array = cv2.imread(os.path.join(path, img))

                    # Resize the image to the specified size
                    new_array = cv2.resize(img_array, (img_size, img_size))

                    # Append the resized image and its class number to the prediction data list
                    pred_Data[i].append([new_array, class_num])

                except Exception as e:
                    # Handle any exceptions that may occur during image processing
                    pass
            i += 1

create_Pred_Data(classes, Datadirectory, fer)

# Initialize lists to hold the data for each class
x_data = [[], [], [], []]

# Initialize a list to hold the corresponding labels
y_data = []

# Initialize a counter
i = 0

# Loop through the prediction data for each class
for sub_fold in pred_Data:
    for features, label in sub_fold:
        # Append the features to the appropriate class's data list
        x_data[i].append(features)

        # If i is 0, add the label to the labels list (assuming labels are the same for all classes)
        if i == 0:
            y_data.append(label)

    i += 1
# Convert the lists to NumPy arrays
for i in range(4):
    x_data[i] = np.array(x_data[i]).reshape(-1, img_size, img_size, 3)

    # Normalize the image data by dividing by 255 (assuming pixel values are in the range 0-255)
    x_data[i] = x_data[i] / 255

    # Convert the array back to a list
    x_data[i] = list(x_data[i])

# Convert the data and labels to NumPy arrays
x_data = np.array(x_data)
y_data = np.array(y_data)

# Assuming x_data contains the data you want to concatenate
data = np.concatenate(x_data, axis=-1)

# Calculate the size of the data array and set the number of rows for reshaping
num_rows = data.shape[0]

# Calculate the number of columns for reshaping
num_columns = data.size // num_rows

# Reshape the data into a 2D array
x_data = data.reshape((num_rows, num_columns))
x_data = x_data.reshape((1, -1))

# Print the shape of the reshaped data
print(x_data.shape)

# Define target class names
target_names = ['Openness', 'Conscientiousness', 'Extraversion', 'Agreeableness', 'Neuroticism']

# Make a prediction using the logistic regression model (lr)
prediction = lr.predict(x_data)

# Print the predicted class label
print("Predicted class label:", target_names[prediction[0]])